{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the REST Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pokemontcgsdk import RestClient\n",
    "import yaml as yaml\n",
    "\n",
    "with open('../sensitive_config/api_config.yaml','r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "RestClient.configure(config['api_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pokemontcgsdk import Card\n",
    "from pokemontcgsdk import Set\n",
    "import dataclasses as dc\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "data_path = Path().cwd().parent / 'data'\n",
    "raw_data_path = data_path / 'raw'\n",
    "partitioned_by_sets_extract_path = raw_data_path / 'sets_partitioned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, Union\n",
    "from functools import reduce\n",
    "\n",
    "## Define the helper methods that convert the SDKs output into JSON-ready outputs\n",
    "def convert_dataclasses_to_dicts(dc_list: Union[list[Card], list[Set]]) -> list[dict]:\n",
    "    \"\"\"Convert a Python dataclass object to a dictionary for serialization to JSON\"\"\"\n",
    "    return map(dc.asdict, dc_list) #[dc.asdict(dataclass) for dataclass in dc_list]\n",
    "\n",
    "def deep_get(dictionary: dict, key_string:str, default:Optional[Any]=None) -> Any:\n",
    "        \"\"\"\n",
    "        This helper function allows a nested key string to be searched within a nested dictionary. \n",
    "        @keystring should use periods to separate keys within the hierarchy levels. Ex: 'set.name' --> dictionary['set']['name']\n",
    "        \"\"\"\n",
    "        return reduce(lambda d,key: d.get(key,default) if isinstance(d,dict) else default, # function\n",
    "                      key_string.split('.'),                                               # sequence\n",
    "                      dictionary)                                                          # intial value\n",
    "\n",
    "def subset_fields_of_interest(data:list[dict], fields:list[str]) -> list[dict]:\n",
    "    \"\"\"Get a subset dictionary from a nested data container dictionary\"\"\"\n",
    "    MISSING_DEFAULT = 'MISSING_KEY'\n",
    "    data_subset = []\n",
    "    for datum in data:\n",
    "        datum_subset: dict = dict()\n",
    "        for field in fields:\n",
    "            value = deep_get(datum, field, default=MISSING_DEFAULT)\n",
    "            if value==MISSING_DEFAULT:\n",
    "                raise KeyError(f'The field \"{field}\" could not be found within the nested hierarchy of the data')\n",
    "            else:\n",
    "                datum_subset[field] = value\n",
    "        data_subset.append(datum_subset)\n",
    "    return data_subset\n",
    "\n",
    "def wrap_with_metadata(data: list[dict]) -> dict:\n",
    "    \"\"\"Add metadata around the pulled data\"\"\"\n",
    "    get_current_time = lambda: datetime.today().strftime('%m/%d/%Y %H:%M:%S')\n",
    "    wrapped_data = {'pulled_on':get_current_time(),\n",
    "                    'count':len(data),\n",
    "                    'data':data}\n",
    "    return wrapped_data\n",
    "\n",
    "def write_to_json(dc_list: Union[list[Card], list[Set]], output_filepath:str,\n",
    "                  fields_of_interest:Optional[list[str]]=None) -> None:\n",
    "    \"\"\"This simplifies the process of writing an SDK Object to JSON files\"\"\"\n",
    "    data = convert_dataclasses_to_dicts(dc_list)\n",
    "    if fields_of_interest is not None:\n",
    "        data = subset_fields_of_interest(data, fields_of_interest)\n",
    "\n",
    "    with open(output_filepath, 'w') as f:\n",
    "        json.dump(wrap_with_metadata(data), f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Catalog of Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_catalog = Set.all()\n",
    "# Convert list of Dataclass objects to list of dictionaries\n",
    "sets_catalog = convert_dataclasses_to_dicts(sets_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ['id','total']\n",
    "sets_catalog_subset = subset_fields_of_interest(sets_catalog, fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'sv6pt5', 'total': 99},\n",
       " {'id': 'sv7', 'total': 175},\n",
       " {'id': 'sv8', 'total': 252},\n",
       " {'id': 'sv8pt5', 'total': 180},\n",
       " {'id': 'sv9', 'total': 190}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets_catalog_subset[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Each Set, Extract the New Price Data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Query String\n",
    "price_capture_fields_of_interest = ['name','id','tcgplayer','legalities', 'set.id']\n",
    "# This is because the Dacite python package that QueryBuilder uses creates a Card dataclass from the response dictionary\n",
    "# So even if the '?select=name,id,...' from price_capture_fields_of_interest is executed with a correct API response,\n",
    "# there are non Optional type fields in the Card dataclass that require definition or an error occurs.\n",
    "mandatory_other_fields = ['images','number','supertype', 'set'] \n",
    "fields_subset = price_capture_fields_of_interest + mandatory_other_fields\n",
    "\n",
    "foi_string = ','.join(fields_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [09:44<00:00,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned query for all card sets executed in 9.745571049054464 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cards_catalog: dict[str, list[Card]] = dict()\n",
    "\n",
    "tic = time.time()\n",
    "for card_set in tqdm(sets_catalog_subset):\n",
    "    set_id = card_set['id']\n",
    "    cards_query = {'q':f'set.id:{set_id}', 'select':foi_string}\n",
    "    data = Card.where(**cards_query)\n",
    "    try:\n",
    "        assert card_set[\"total\"] != len(data)\n",
    "    except AssertionError as e:\n",
    "        e.add_note(f'Set \"{set_id}\" expected {card_set[\"total\"]} cards, got {len(data)} card data entries')\n",
    "    cards_catalog[set_id] = data\n",
    "\n",
    "toc = time.time()\n",
    "print(f'Partitioned query for all card sets executed in {(toc-tic)/60.0} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 165/165 [00:06<00:00, 25.15it/s]\n"
     ]
    }
   ],
   "source": [
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "for set_id, data in tqdm(cards_catalog.items()):\n",
    "    file_name = partitioned_by_sets_extract_path /  f'{today}_SET_{set_id}.json'\n",
    "    write_to_json(data, file_name, price_capture_fields_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
